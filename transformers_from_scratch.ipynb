{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e2591c-2aa4-4755-b20b-e6215db59cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017ae835",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 5, bias=False, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b311a958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ab2375-202a-478a-a01d-3816ab5ae68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume \n",
    "batch_size = 32\n",
    "seq_len = 10\n",
    "N = 4\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, N)\n",
    "raw_weights = torch.bmm(x, x.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c765d5-274b-4bb1-b2a4-6a68baea6293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9d6693d-3295-4607-9dfb-8db1cf334ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.transpose(1, 2).contiguous()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc604a7b-1580-4720-9dae-70505e1e8f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7630,  0.6042, -0.3009,  ...,  1.4541, -1.4075, -0.0840],\n",
       "         [ 0.5463, -0.3298, -0.0373,  ...,  0.9029,  0.8614,  0.1479],\n",
       "         [ 0.3253,  0.4925,  0.7287,  ...,  0.1725, -0.2038,  1.3128],\n",
       "         [-0.6950, -0.2766,  0.4072,  ...,  0.6336,  0.2290, -0.3056]],\n",
       "\n",
       "        [[ 1.3034, -0.8500,  0.8639,  ...,  1.4423,  1.7732,  1.4420],\n",
       "         [-0.4350, -1.5608, -0.0585,  ...,  0.8729,  1.0806,  0.1019],\n",
       "         [ 0.1021, -0.2605, -0.0435,  ..., -1.1443, -0.7740,  0.4617],\n",
       "         [ 0.9360, -0.3276,  0.7518,  ..., -0.4964,  1.0971,  0.6500]],\n",
       "\n",
       "        [[ 0.1747,  0.9367,  0.3179,  ..., -0.2144,  0.0483,  0.7049],\n",
       "         [ 2.4926,  1.0518, -1.6349,  ...,  0.3182, -1.1450,  0.4416],\n",
       "         [ 1.9857, -0.0313, -1.2208,  ..., -0.0224, -0.3288,  0.7385],\n",
       "         [ 0.4569, -0.2774, -0.6974,  ...,  1.3395,  0.7676, -1.7763]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0245,  0.1883,  1.6618,  ...,  1.5760, -0.0209, -0.8999],\n",
       "         [ 2.1933,  0.3406,  0.9471,  ...,  0.4746,  0.5330, -1.9053],\n",
       "         [ 0.1312,  0.6775,  0.6283,  ..., -0.8531, -0.8916, -0.9300],\n",
       "         [ 0.4248,  0.5792,  1.0524,  ..., -1.1142, -1.1804,  0.0187]],\n",
       "\n",
       "        [[ 0.2029,  1.2103, -0.8449,  ..., -0.8766, -0.5963,  0.2473],\n",
       "         [-2.2579, -1.9487, -0.2122,  ..., -0.5566,  0.9019,  0.2261],\n",
       "         [-1.0768,  1.4800, -1.4219,  ...,  0.5501, -2.4250,  0.1624],\n",
       "         [ 0.2941,  0.8727,  1.4577,  ...,  1.1075,  0.6654, -0.8368]],\n",
       "\n",
       "        [[-0.1172, -0.4489, -0.8119,  ..., -0.3393, -1.1675, -0.7344],\n",
       "         [-1.0276, -1.2001,  1.2850,  ...,  0.3555,  0.6492, -0.7504],\n",
       "         [-0.5034, -1.9786,  0.5127,  ..., -0.3394,  2.0345, -2.4355],\n",
       "         [-0.7052, -0.7588, -0.9171,  ...,  0.0831, -0.5599,  0.5884]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f837e99-9c84-491b-a1c4-a31a6bb6426e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7630,  0.6042, -0.3009,  ...,  1.4541, -1.4075, -0.0840],\n",
       "         [ 0.5463, -0.3298, -0.0373,  ...,  0.9029,  0.8614,  0.1479],\n",
       "         [ 0.3253,  0.4925,  0.7287,  ...,  0.1725, -0.2038,  1.3128],\n",
       "         [-0.6950, -0.2766,  0.4072,  ...,  0.6336,  0.2290, -0.3056]],\n",
       "\n",
       "        [[ 1.3034, -0.8500,  0.8639,  ...,  1.4423,  1.7732,  1.4420],\n",
       "         [-0.4350, -1.5608, -0.0585,  ...,  0.8729,  1.0806,  0.1019],\n",
       "         [ 0.1021, -0.2605, -0.0435,  ..., -1.1443, -0.7740,  0.4617],\n",
       "         [ 0.9360, -0.3276,  0.7518,  ..., -0.4964,  1.0971,  0.6500]],\n",
       "\n",
       "        [[ 0.1747,  0.9367,  0.3179,  ..., -0.2144,  0.0483,  0.7049],\n",
       "         [ 2.4926,  1.0518, -1.6349,  ...,  0.3182, -1.1450,  0.4416],\n",
       "         [ 1.9857, -0.0313, -1.2208,  ..., -0.0224, -0.3288,  0.7385],\n",
       "         [ 0.4569, -0.2774, -0.6974,  ...,  1.3395,  0.7676, -1.7763]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0245,  0.1883,  1.6618,  ...,  1.5760, -0.0209, -0.8999],\n",
       "         [ 2.1933,  0.3406,  0.9471,  ...,  0.4746,  0.5330, -1.9053],\n",
       "         [ 0.1312,  0.6775,  0.6283,  ..., -0.8531, -0.8916, -0.9300],\n",
       "         [ 0.4248,  0.5792,  1.0524,  ..., -1.1142, -1.1804,  0.0187]],\n",
       "\n",
       "        [[ 0.2029,  1.2103, -0.8449,  ..., -0.8766, -0.5963,  0.2473],\n",
       "         [-2.2579, -1.9487, -0.2122,  ..., -0.5566,  0.9019,  0.2261],\n",
       "         [-1.0768,  1.4800, -1.4219,  ...,  0.5501, -2.4250,  0.1624],\n",
       "         [ 0.2941,  0.8727,  1.4577,  ...,  1.1075,  0.6654, -0.8368]],\n",
       "\n",
       "        [[-0.1172, -0.4489, -0.8119,  ..., -0.3393, -1.1675, -0.7344],\n",
       "         [-1.0276, -1.2001,  1.2850,  ...,  0.3555,  0.6492, -0.7504],\n",
       "         [-0.5034, -1.9786,  0.5127,  ..., -0.3394,  2.0345, -2.4355],\n",
       "         [-0.7052, -0.7588, -0.9171,  ...,  0.0831, -0.5599,  0.5884]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628ca61c-a7f6-47bc-91f4-fe09b2b40211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852f2443-c0b6-4db3-9fb5-bd8d7d717763",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.softmax(raw_weights, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba14ac67-3d16-46fb-9c2f-1763da5f1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.bmm(weights, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2570660f-fccf-43f0-a432-3d066ac1343f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a2e7b-c8a7-4185-b7f3-56af315cae7b",
   "metadata": {},
   "source": [
    "### Multi-head, Self-Attention Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d85f89b-60a8-40f9-b09d-334b8eb449bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, k, heads=8):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.heads = 8\n",
    "        \n",
    "        # queries, keys, values\n",
    "        self.tokeys = nn.Linear(k, k*heads, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k*heads, bias=False)\n",
    "        self.tovalues = nn.Linear(k, k*heads, bias=False)\n",
    "        \n",
    "        # Unify outputs of multiple heads to one\n",
    "        self.unifyheads = nn.Linear(k*heads, k)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, t, k = x.size()\n",
    "        h = self.heads\n",
    "        \n",
    "        queries = self.toqueries(x).view(b, t, h, k)\n",
    "        keys = self.toqueries(x).view(b, t, h, k)\n",
    "        values = self.tovalues(x).view(b, t, h, k)\n",
    "        \n",
    "        keys = keys.transpose(1, 2).contiguous().view(b*h, t, k)\n",
    "        \n",
    "        queries = queries / (k ** (1/4))\n",
    "        keys = keys / (k ** (1/4))\n",
    "        \n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        # Apply attention to values\n",
    "        out = torch.bmm(dot, values).view(b, h, t, k)\n",
    "        out.transpose(1, 2).contiguous().view(b, t, h*k)\n",
    "        \n",
    "        return self.unifyheads(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c6f1a5-ac81-4366-8c1c-3bca4ffd27d0",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "835df7dd-94fc-4451-8da2-4afdaa565980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, k, heads):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(k, heads)\n",
    "        self.norm1 = nn.LayerNorm()\n",
    "        self.norm2 = nn.LayerNorm()\n",
    "        \n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(k, 4*k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*k, k))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attended = self.attention(x)\n",
    "        x = self.norm1(x+attention)\n",
    "        fedforward = self.ff(x)\n",
    "        return self.norm2(x+fedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c29ae8-8c2f-4f7b-a6a8-f608f947d246",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78ad7b-aeb6-4542-9bf1-8a20346ee7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, k, heads, depth, seq_length, num_tokens, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_emb = nn.Embedding(num_tokens, k)\n",
    "        self.pos_emb = nn.Embedding(seq_length, k)\n",
    "        \n",
    "        # Sequence of Transformer Block\n",
    "        trans_blocks = []\n",
    "        for i in range(depth):\n",
    "            trans_blocks.append(TransformerBlock(k, heads))\n",
    "        self.trans_blocks = nn.Sequential(*trans_blocks)\n",
    "        \n",
    "        self.toprobs = nn.Linear(k, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tokens = self.token_emb(x)\n",
    "        b, t, k = tokens.size()\n",
    "        \n",
    "        positions = torch.arange(t)\n",
    "        positions = self.pos_emb(positions)[None, :, :].expand(b, t, k)\n",
    "        \n",
    "        x = tokens + positions\n",
    "        x = self.trans_blocks(x)\n",
    "        \n",
    "        x = self.toprobs(x.mean(dim=1))\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2c72f-766e-44fe-8ae0-baa5e59d074c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bea86-4a09-4923-9a38-66db38a171e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21c1ca-9190-4696-9d54-a5bab6b3cc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8356bb462cc4223ae8e382e17ef061f30ff45b14e50fa81967e59a7123534447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
